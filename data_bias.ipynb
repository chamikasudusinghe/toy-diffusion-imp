{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p6Yk8Vt69j1q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from diffusion import q_sample, posterior_q, Denoising, denoise_with_mu\n",
        "from utils import pack_data, unpack_1d_data, scatter_pixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjEpWmDS4QV5"
      },
      "outputs": [],
      "source": [
        "!pip install diffusers[training]==0.5.1\n",
        "!pip install celluloid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "A32ARt3G-dFj"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "LOh7IHgg4Eyc"
      },
      "outputs": [],
      "source": [
        "from diffusers import DDPMScheduler\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "from operator import mul\n",
        "from functools import reduce \n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "from celluloid import Camera\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm \n",
        "\n",
        "#homer = Image.open('homer.png')\n",
        "\n",
        "#noise_scheduler = DDPMScheduler(num_train_timesteps=10)\n",
        "#conver_tensor = transforms.ToTensor()\n",
        "#homer_sample = conver_tensor(homer)\n",
        "\n",
        "#noise = torch.randn(1)\n",
        "#timesteps = torch.LongTensor([1])\n",
        "#noisy_image = noise_scheduler.add_noise(homer_sample, noise, timesteps)\n",
        "\n",
        "#noisy_homer = Image.fromarray((noisy_image.permute(0, 1, 2) * 255).type(torch.uint8).numpy()[0])\n",
        "#noisy_homer.save('noisy_homer.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Xsfz3qbY-i5C"
      },
      "outputs": [],
      "source": [
        "#x,y = scatter_pixels('noisy_homer.png')\n",
        "imageList = ['homer.png','homer1.png']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rOe_X-GI7aXv"
      },
      "outputs": [],
      "source": [
        "#ax = sns.scatterplot(x,y)\n",
        "\n",
        "## Store the ax to plot the result later\n",
        "#y_ax = ax.get_ylim()\n",
        "#x_ax = ax.get_xlim()\n",
        "#axes = (x_ax,y_ax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QMusrIlu_PM3",
        "outputId": "2a374544-8357-4ae7-e9b3-00837c12c8e4"
      },
      "outputs": [],
      "source": [
        "x_new = []\n",
        "y_new = []\n",
        "for img in imageList:\n",
        "  x,y = scatter_pixels(img)\n",
        "  x = x+x_new\n",
        "  y = y+y_new\n",
        "\n",
        "  x = [x/25 -3 for x in x]\n",
        "  y = [y/25 -2 for y in y]\n",
        "\n",
        "  # send data to device\n",
        "  one_d_data = pack_data(x,y)\n",
        "  x_init = torch.tensor(one_d_data).to(torch.float32).to(device)\n",
        "  DATA_SIZE = len(x_init)\n",
        "\n",
        "  beta_start = .0004\n",
        "  beta_end = .02\n",
        "  num_diffusion_timesteps = 10\n",
        "\n",
        "  betas = np.linspace(beta_start ** 0.5, beta_end ** 0.5, num_diffusion_timesteps) ** 2\n",
        "  alphas = 1 - betas\n",
        "\n",
        "  # send parameters to device\n",
        "  betas = torch.tensor(betas).to(torch.float32).to(device)\n",
        "  alphas = torch.tensor(alphas).to(torch.float32).to(device)\n",
        "\n",
        "  # alpha_bar_t is the product of all alpha_ts from 0 to t\n",
        "  list_bar_alphas = [alphas[0]]\n",
        "  for t in range(1,num_diffusion_timesteps):\n",
        "      list_bar_alphas.append(reduce(mul,alphas[:t]))\n",
        "      \n",
        "  list_bar_alphas = torch.cumprod(alphas, axis=0).to(torch.float32).to(device)\n",
        "\n",
        "  training_steps_per_epoch = 10\n",
        "\n",
        "  criterion = nn.MSELoss()\n",
        "  denoising_model = Denoising(DATA_SIZE, num_diffusion_timesteps).to(device)\n",
        "  # disgusting hack to put embedding layer on 'device' as well, as it is not a pytorch module!\n",
        "  denoising_model.emb = denoising_model.emb.to(device)\n",
        "  optimizer = optim.AdamW(denoising_model.parameters())\n",
        "\n",
        "  pbar = tqdm(range(50))\n",
        "\n",
        "  for epoch in pbar:  # loop over the dataset multiple times\n",
        "      \n",
        "      running_loss = 0.0\n",
        "      # sample a bunch of timesteps\n",
        "      Ts = np.random.randint(1,num_diffusion_timesteps, size=training_steps_per_epoch)\n",
        "      for _, t in enumerate(Ts):\n",
        "          # produce corrupted sample\n",
        "          q_t = q_sample(x_init, t, list_bar_alphas, device)\n",
        "                  \n",
        "          # calculate the mean and variance of the posterior forward distribution q(x_t-1 | x_t,x_0)\n",
        "          mu_t, cov_t = posterior_q(x_init, q_t, t, alphas, list_bar_alphas, device)\n",
        "          # get just first element from diagonal of covariance since they are all equal\n",
        "          sigma_t = cov_t[0][0]\n",
        "          # zero the parameter gradients\n",
        "          optimizer.zero_grad()\n",
        "    \n",
        "          mu_theta = denoising_model(q_t , t)\n",
        "          loss = criterion(mu_t, mu_theta)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          running_loss += loss.detach()\n",
        "      pbar.set_description('Epoch: {} Loss: {}'.format(epoch, running_loss/training_steps_per_epoch))\n",
        "  print('Finished Denising with an Image')\n",
        "  data = torch.distributions.MultivariateNormal(loc=torch.zeros(DATA_SIZE),covariance_matrix=torch.eye(DATA_SIZE)).sample().to(device)\n",
        "\n",
        "  for t in tqdm(range(0,num_diffusion_timesteps)):\n",
        "    data = denoise_with_mu(denoising_model,data,num_diffusion_timesteps-t-1, alphas, list_bar_alphas, DATA_SIZE, device)\n",
        "  data = data.detach().cpu().numpy()\n",
        "  x_new, y_new = unpack_1d_data(data)\n",
        "  sns.scatterplot(x_new,y_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQUH7jAZBR_H"
      },
      "outputs": [],
      "source": [
        "#data = data.detach().cpu().numpy()\n",
        "#x_new, y_new = unpack_1d_data(data)\n",
        "\n",
        "sns.scatterplot(x_new,y_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27WI0W7wCEUb"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "camera = Camera(fig)\n",
        "\n",
        "# animation draws one data point at a time\n",
        "for d in range(1, num_diffusion_timesteps):\n",
        "    data = denoise_with_mu(denoising_model,data,num_diffusion_timesteps-d, alphas, list_bar_alphas, DATA_SIZE, device)\n",
        "    data_plot = data.detach().cpu().numpy()\n",
        "    x_new, y_new = unpack_1d_data(data_plot)\n",
        "    graph = sns.scatterplot(x=x_new,y=y_new,palette=['green'])\n",
        "    graph.set_xlim(axes[0])\n",
        "    graph.set_ylim(axes[1])\n",
        "    camera.snap()\n",
        "\n",
        "anim = camera.animate(blit=False)\n",
        "anim.save('output.mp4',fps=24, dpi=120)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
